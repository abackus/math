% --------------------------------------------------------------
% This is all preamble stuff that you don't have to worry about.
% Head down to where it says "Start here"
% --------------------------------------------------------------

\documentclass[10pt]{beamer}

% \usepackage[margin=1in]{geometry}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{enumitem}
\usepackage{tikz}
\usepackage{wrapfig}
\usepackage{cjhebrew}
% \usepackage[shortlabels]{enumerate}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usetikzlibrary{calc}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{arrows}

\newcommand{\NN}{\mathbb{N}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\CC}{\mathbb{C}}

\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\Exc}{Exc}
\newcommand{\normal}{\vec n}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\newcommand{\Spec}{\operatorname{Spec}}

\renewcommand{\Re}{\operatorname{Re}}
\renewcommand{\Im}{\operatorname{Im}}

\newtheorem{conjecture}{Conjecture}
\newtheorem{question}{Question}

\usepackage[backend=bibtex,style=alphabetic,maxcitenames=50,maxnames=50]{biblatex}
\addbibresource{ultrapowerful.bib}
\renewbibmacro{in:}{}
\DeclareFieldFormat{pages}{#1}

\usetheme{AnnArbor}
\usecolortheme{dove}

\begin{document}
\title{The least-gradient maximum principle}
\author{Aidan Backus}
% --------------------------------------------------------------
%                         Start here
% --------------------------------------------------------------
\begin{frame}
    \titlepage
\end{frame}

\begin{frame}{Least-gradient problem}
Consider the problem of finding
$$\argmin_{u|\partial \Omega = v} \int_\Omega |\nabla u|$$
where the domain $\Omega$ and boundary data $v: \partial \Omega \to \RR$ are given, and $u \in BV(\Omega)$ (ie, $u$ may have jump discontinuities).
\end{frame}

\begin{frame}{Motivation from magnetic resonance imaging}
    Suppose $\sigma(x)$ tells you how conductive the region $\Omega$ is at $x$. How to determine $\sigma$? \pause

    Fix a voltage $v$ on $\partial \Omega$. It induces a current $J$ and we can measure $|J|$ using MRI. The potential $u$ is
    \begin{equation}\label{weighted least gradient problem}
    \argmin_{u|\partial \Omega = v} \int_\Omega |J| \cdot |\nabla u|.
    \end{equation}
    Then $\sigma = |J|/|\nabla u|$. \pause

    Geometric POV: If we endow $\Omega$ with the Riemannian metric $g_{\mu\nu} = |J|^{2/(d + 1)}\delta_{\mu\nu}$ then (\ref{weighted least gradient problem}) is just the least-gradient problem!
\end{frame}

\begin{frame}{Motivation from geometric analysis}
    A line in $\RR^2$ is the shortest path between two points. We generalize this as follows:\pause

    \begin{definition}
    Let $M$ be a Riemannian manifold of dimension $d$, $\Omega \subseteq M$ open. A \emph{minimal hypersurface} $N$ is a smooth submanifold which has dimension $d - 1$ and solves the problem
    $$\argmin_{N \cap \partial \Omega = S} |N|$$
    where $|\cdot|$ denotes surface area and $S$ is given.
    \end{definition}\pause
    
    If $N$ bounds an open set $U$, then $1_U$ has least gradient. Conversely, if $1_U$ has least gradient \emph{and $N$ is smooth} then $N$ is a minimal hypersurface.
\end{frame}

\begin{frame}{The maximum principle}
\begin{theorem}[de Giorgi--Miranda--Simons '68]
Let $M = \RR^d$ where $d \leq 7$, and let $u$ be a function of least gradient, $y \in \RR$. Then $\partial \{u > y\}$ is a smooth minimal hypersurface.
\end{theorem}
\pause
More natural to do this in Riemannian manifolds.
\begin{theorem}[B. '22]
Same result, but this time $M$ has constant negative curvature and dimension $\leq 7$.
\end{theorem}
\pause
Application: Loisel ('20) numerically solved the least-gradient problem. Combine this fact with the maximum principle to make some pretty pictures of minimal surfaces.
\end{frame}

\begin{frame}{Pictures of minimal hypersurfaces}
Do a line in $\RR^2$, a soap film in $\RR^3$, and their analogues on a genus-$2$ curve over $\CC$.
\end{frame}

\begin{frame}{Proving the maximum principle}
Assume that $N = \partial \{u > 0\}$ where $u$ is least gradient.
Let $\mu$ be the surface measure on $N$, and let $\normal$ be the normal vector field to $N$ (so $\normal$ is $\mu$-measurable.) \pause If $\normal$ is continuous, then $N$ can be written as the graph of a $C^1$ function $\omega$ on $\RR^{d - 1}$ which solves Plateau's equation, in negative curvature it looks like
\begin{equation}\label{Plateau}
\nabla \cdot \frac{\nabla \omega}{\sqrt{1 + |\nabla \omega|^2}} = F(\omega, \nabla \omega).
\end{equation}
(\ref{Plateau}) is elliptic so $\omega$ and therefore $N$ is smooth.
\end{frame}

\begin{frame}{Induction: base case}
Must show that $\normal$ is continuous. The \emph{excess} (in suitable coordinates)
$$\Exc_n := 2^{n(d - 1)} \left(\mu(B_{2^{-n}}) - \sqrt{\sum_i\left(\int_{B_{2^{-n}}} \normal_i ~d\mu\right)^2} \right)$$
measures how much $\normal$ oscillates in $B_{2^{-n}}$ and we need to show that $\Exc_n \lesssim (0.51)^n$ (say). This can be shown by induction:\pause
\begin{itemize}
\item Base case: For every $\sigma > 0$ there exists $n$ such that $\Exc_n < \sigma$.\pause
\item Inductive case: There exists $\sigma > 0$ such that if $\Exc_n < \sigma$ then $\Exc_{n + 1} < 0.51 \cdot \Exc_n$.\pause
\end{itemize}
Base case is where we use $d \leq 7$ (but not the curvature). In the ball $B_{2^{-n}}$ with $n \gg 1$, $N$ looks like a minimal cone in $\RR^d$, and those have been classified for $d \leq 7$: they're all hyperplanes and therefore have $\Exc_n = 0$.
\end{frame}

\begin{frame}{Induction: Inductive case}
The inductive step is a lot more delicate:\pause
\begin{itemize}
\item Approximate $N$ by the graph of a $C^1$ function $\omega$ (easiest if Ricci is negative). \pause
\item If $\Exc_n$ is small then $|\nabla \omega|$ is small.\pause
\item Linearize Plateau's equation around $\nabla \omega = 0$ to get a linear elliptic PDE $P\omega = 0$.\pause
\item Small miracle: for manifolds of constant negative curvature, there are coordinates in which $P$ is the \emph{euclidean} Laplace operator!! (NOT true for $M$ a sphere, say.)\pause
\item Conclude the inductive case by using the mean-value property of $P$... almost.\pause 
\item Pick up a bunch of junk terms in negative curvature, but by being very careful we can make most of them cancel out, what's left is $< 0.01\Exc_n$.
\end{itemize}
\end{frame}

\begin{frame}{Fin}
    Thanks for coming!
\end{frame}

\end{document}
