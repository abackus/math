\documentclass[reqno,11pt]{amsart}
\usepackage[letterpaper, margin=1in]{geometry}
\RequirePackage{amsmath,amssymb,amsthm,graphicx,mathrsfs,url,slashed,subcaption}
\RequirePackage[usenames,dvipsnames]{xcolor}
\RequirePackage[colorlinks=true,linkcolor=Red,citecolor=Green]{hyperref}
\RequirePackage{amsxtra}
\usepackage{cancel}
\usepackage{tikz-cd}
%\usepackage[T1]{fontenc}

% \setlength{\textheight}{9.3in} \setlength{\oddsidemargin}{-0.25in}
% \setlength{\evensidemargin}{-0.25in} \setlength{\textwidth}{7in}
% \setlength{\topmargin}{-0.25in} \setlength{\headheight}{0.18in}
% \setlength{\marginparwidth}{1.0in}
% \setlength{\abovedisplayskip}{0.2in}
% \setlength{\belowdisplayskip}{0.2in}
% \setlength{\parskip}{0.05in}
%\renewcommand{\baselinestretch}{1.05}

\title{Many calibrations}
\author{Aidan Backus}
\address{Department of Mathematics, Brown University}
\email{aidan\_backus@brown.edu}
\date{\today}
\keywords{}
\subjclass[2020]{}

\newcommand{\NN}{\mathbf{N}}
\newcommand{\ZZ}{\mathbf{Z}}
\newcommand{\QQ}{\mathbf{Q}}
\newcommand{\RR}{\mathbf{R}}
\newcommand{\CC}{\mathbf{C}}
\newcommand{\DD}{\mathbf{D}}
\newcommand{\PP}{\mathbf P}
\newcommand{\MM}{\mathbf M}
\newcommand{\II}{\mathbf I}
\newcommand{\Hyp}{\mathbf H}
\newcommand{\Sph}{\mathbf S}
\newcommand{\Group}{\mathbf G}
\newcommand{\GL}{\mathbf{GL}}
\newcommand{\Orth}{\mathbf{O}}
\newcommand{\SpOrth}{\mathbf{SO}}
\newcommand{\Ball}{\mathbf{B}}

\newcommand*\dif{\mathop{}\!\mathrm{d}}

\DeclareMathOperator{\card}{card}
\DeclareMathOperator{\dist}{dist}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\coker}{coker}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\Teich}{Teich}
\DeclareMathOperator{\tr}{tr}

\newcommand{\Leaves}{\mathscr L}
\newcommand{\Lagrange}{\mathcal L}
\newcommand{\Hypspace}{\mathscr H}

\newcommand{\Chain}{\underline C}

\newcommand{\Two}{\mathrm{I\!I}}

\newcommand{\normal}{\mathbf n}
\newcommand{\radial}{\mathbf r}
\newcommand{\evect}{\mathbf e}
\newcommand{\vol}{\mathrm{vol}}

\newcommand{\Bl}{\operatorname{Bl}}
\newcommand{\diam}{\mathrm{diam}}
\newcommand{\Ell}{\mathrm{Ell}}
\newcommand{\inj}{\mathrm{inj}}
\newcommand{\Lip}{\mathrm{Lip}}
\newcommand{\MCL}{\mathrm{MCL}}
\newcommand{\Riem}{\mathrm{Riem}}

\newcommand{\Mass}{\mathbf M}
\newcommand{\Comass}{\mathbf L}

\newcommand{\weakto}{\rightharpoonup}

\newcommand{\Min}{\mathrm{Min}}
\newcommand{\Max}{\mathrm{Max}}

\newcommand{\dfn}[1]{\emph{#1}\index{#1}}

\renewcommand{\Re}{\operatorname{Re}}
\renewcommand{\Im}{\operatorname{Im}}

\newcommand{\loc}{\mathrm{loc}}
\newcommand{\cpt}{\mathrm{cpt}}

\def\Japan#1{\left \langle #1 \right \rangle}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{badtheorem}[theorem]{``Theorem"}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{sublemma}[theorem]{Sublemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{axiom}[theorem]{Axiom}
\newtheorem{assumption}[theorem]{Assumption}

\newtheorem{mainthm}{Theorem}
\renewcommand{\themainthm}{\Alph{mainthm}}

\newtheorem{claim}{Claim}[theorem]
\renewcommand{\theclaim}{\thetheorem\Alph{claim}}
% \newtheorem*{claim}{Claim}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}
\newtheorem{notation}[theorem]{Notation}

\newtheorem{exercise}[theorem]{Discussion topic}
\newtheorem{homework}[theorem]{Homework}
\newtheorem{problem}[theorem]{Problem}

\makeatletter
\newcommand{\proofpart}[2]{%
  \par
  \addvspace{\medskipamount}%
  \noindent\emph{Part #1: #2.}
}
\makeatother

\DeclareMathOperator*{\essinf}{ess\,inf}
\DeclareMathOperator*{\esssup}{ess\,sup}


\numberwithin{equation}{section}


% Mean
\def\Xint#1{\mathchoice
{\XXint\displaystyle\textstyle{#1}}%
{\XXint\textstyle\scriptstyle{#1}}%
{\XXint\scriptstyle\scriptscriptstyle{#1}}%
{\XXint\scriptscriptstyle\scriptscriptstyle{#1}}%
\!\int}
\def\XXint#1#2#3{{\setbox0=\hbox{$#1{#2#3}{\int}$ }
\vcenter{\hbox{$#2#3$ }}\kern-.6\wd0}}
\def\ddashint{\Xint=}
\def\dashint{\Xint-}

\usepackage[backend=bibtex,style=alphabetic,giveninits=true]{biblatex}
\renewcommand*{\bibfont}{\normalfont\footnotesize}
\addbibresource{best_curl.bib}
\renewbibmacro{in:}{}
\DeclareFieldFormat{pages}{#1}

\newcommand\todo[1]{\textcolor{red}{TODO: #1}}


\begin{document}
\maketitle

\section{Introduction}
Let $M$ be a closed Riemannian manifold of dimension $d \geq 2$, and let $k \in \{1, \dots, d - 1\}$.
A \dfn{$k$-blade} at $x \in M$ is a wedge product of the form $v := v_1 \wedge \dots \wedge v_n$, $v_i \in T_x M$; in this case we write $v \in B_{x, k} M$.
The \dfn{comass} of a $k$-form $\varphi$ is
$$\Comass(\varphi) = \esssup_{x \in M} \max_{v \in B_{x, k} M} \langle \varphi(x), v\rangle.$$
The \dfn{costable norm} of a cohomology class $\rho \in H^k(M, \RR)$ is
$$\Comass(\rho) := \inf_{[\varphi] = \rho} \Comass(\varphi).$$
I think that since $M$ is closed, the costable norm really is a (positive-definite) norm on $H^k(M, \RR)$.

\begin{mainthm}\label{existence of calibrations}
Let $\rho \in H^k(M, \RR)$ satisfy $\Comass(\rho) = 1$.
Then there is a measurable calibration $\varphi$ which represents $\rho$, and a closed $k$-current $T$ which is calibrated by $\varphi$:
$$\langle T, \varphi\rangle = \Mass(T).$$
\end{mainthm}

\section{Singular value decomposition of differential forms}
Let $V$ be a Hilbert space of dimension $d < \infty$.
We denote by $\Bl_k(V) \subseteq V^{\wedge k}$ the set of $k$-blades over $V$, and record for future reference that
$$\dim V^{\wedge k} = \binom dk.$$
If $v, w \in \Bl_k(V)$, let
$$\langle v, w\rangle := \det(\langle v_i, w_j\rangle_{ij}),$$
which extends to an inner product on $V^{\wedge k}$ in the natural way.

Let $\varphi \in V^{\wedge k}$.
We define
\begin{equation}\label{first singular value}
\sigma_1(\varphi) := \max_{\substack{v \in \Bl_k(V) \\ |v| \leq 1}} \langle \varphi, v\rangle,
\end{equation}
and let $\xi_1(\varphi) \in \Bl_k(V)$ realize the maximum in (\ref{first singular value}).
We can then inductively define 
\begin{equation}\label{low singular value}
\sigma_{j + 1}(\varphi) := \max_{\substack{v \in \Bl_k(V) \\ |v| \leq 1 \\ v \perp \xi_1(\varphi), \cdots, \xi_j(\varphi)}} \langle \varphi, v\rangle,
\end{equation}
and let $\xi_{j + 1}(\varphi) \in \Bl_k(V)$ realize the maximum in (\ref{low singular value}).
Then $\sigma_j(\varphi) \geq \sigma_{j + 1}(\varphi)$, $\xi_1(\varphi), \dots, \xi_{\binom dk}(\varphi)$ is an orthonormal basis of $V^{\wedge k}$, and
\begin{equation}\label{SVD of a form}
\varphi = \sum_{j = 1}^{\binom dk} \sigma_j(\varphi) \xi_j(\varphi).
\end{equation}
Moreover, since $\Bl_k(V)$ spans $V^{\wedge k}$,
\begin{equation}\label{seminorms are norms}
\sigma_1(\varphi) = 0 \implies \varphi = 0.
\end{equation}

\begin{definition}
The \dfn{singular value decomposition} of $\varphi \in V^{\wedge k}$ is defined as (\ref{SVD of a form}), where $\sigma_j(\varphi)$ and $\xi_j(\varphi)$ are defined by (\ref{first singular value}) and (\ref{low singular value}).
\end{definition}

If $V$ is (a typical fiber of) the cotangent bundle of $M$, and $\varphi$ is a $k$-form on $M$, then
$$\Comass(\varphi) = \esssup_{x \in M} \sigma_1(\varphi(x)).$$
Unfortunately $\sigma_1$ is not a strictly convex norm on $V^{\wedge k}$, so we introduce approximations:

\begin{definition}
Let $p \in [1, \infty)$.
The $p$th \dfn{Schatten-von Neumann norm} on $V^{\wedge k}$ is 
$$|\varphi|_p := \left(\sum_{j = 1}^{\binom dk} \sigma_j(\varphi)^p\right)^{1/p}.$$
We moreover define 
$$|\varphi|_\infty := \sigma_1(\varphi).$$
\end{definition}

Since $|\varphi|_p$ is the $\ell^p$ norm of $(\sigma_1(\varphi), \dots, \sigma_{\binom dk}(\varphi))$, $p \in [1, \infty]$, and $\ell^p$ norms converge to the $\ell^\infty$ norm as $p \to \infty$,
\begin{equation}\label{SvN norms converge}
|\varphi|_\infty = \lim_{p \to \infty} |\varphi|_p.
\end{equation}
In order to prove properties about $|\cdot|_p$ it is convenient to introduce another family of norms.

\begin{definition}
Let $\ell \in \{1, \dots, \binom dk\}$.
The $\ell$th \dfn{Ky Fan norm} on $V^{\wedge k}$ is 
$$|\varphi|_{KF,\ell} := \sum_{j=1}^\ell \sigma_j(\varphi).$$
\end{definition}

\begin{lemma}
The Ky Fan norm $|\cdot|_{KF, \ell}$ is a norm on $V^{\wedge k}$.
\end{lemma}
\begin{proof}
Let $\varphi, \psi \in V^{\wedge k}$.
Immediately from the definitions we have the \dfn{Ky Fan maximum principle} that 
$$|\varphi|_{KF, \ell} = \max_{v^1, \dots, v^\ell} \sum_{j=1}^\ell \langle \varphi, v^j\rangle$$
where the maximum is taken over all orthonormal sets $\{v^1, \dots, v^\ell\} \subset \Bl_k(V)$.
(Indeed, the maximum is taken by $v^j = \xi_j(\varphi)$.)
Thus we have 
\begin{align*}
|\varphi + \psi|_{KF, \ell}
&= \max_{v^1, \dots, v^\ell} \sum_{j=1}^\ell \langle \varphi, v^j\rangle + \langle \psi, v^j\rangle \\
&\leq \max_{v^1, w^1, \dots, v^\ell, w^\ell} \sum_{j=1}^\ell \langle \varphi, v^j\rangle + \langle \psi, w^j\rangle \\
&= |\varphi|_{KF, \ell} + |\psi|_{KF, \ell}
\end{align*}
where the first maximum is taken over orthonormal sets $\{v^1, \dots, v^\ell\} \subset \Bl_k(V)$ and the second is taken over pairs of orthonormal sets 
$$\{v^1, \dots, v^\ell\}, \{w^1, \dots, w^\ell\} \subset \Bl_k(V).$$
It follows that the Ky Fan norms are seminorms on $V^{\wedge k}$.
Moreover, if $|\varphi|_{KF,\ell} = 0$, then $\sigma_1(\varphi) = 0$, so $\varphi = 0$ by (\ref{seminorms are norms}); therefore $|\cdot|_{KF, \ell}$ is a norm.
\end{proof}


\begin{lemma}
The Schatten-von Neumann norm $|\cdot|_p$, $p \in [1, \infty]$, is a norm on $V^{\wedge k}$.
\end{lemma}
\begin{proof}
Setting $m := \binom dk$, $x_i := \sigma_i(\varphi + \psi)$, and $y_i := \sigma_i(\varphi) + \sigma_i(\psi)$, it follows from the Ky Fan triangle inequality that (\ref{Ky Fan gives SvN hyp}) holds.
Thus by (\ref{Ky Fan gives SvN concl}), for any $p \in [1, \infty)$,
\begin{equation}\label{proving SvN is a norm}
|\varphi + \psi|_p \leq (|\varphi|_p^p + |\psi|_p^p)^{1/p} \leq |\varphi|_p + |\psi|_p,
\end{equation}
establishing the triangle inequality for $|\cdot|_p$.
It follows from (\ref{seminorms are norms}) that $|\cdot|_p$ is a norm, and then by (\ref{SvN norms converge}) that $|\cdot|_\infty$ is a norm.
\end{proof}


\begin{lemma}[von Neumann and H\"older inequalities]
Let $\varphi, \psi \in V^{\wedge k}$, and let $(p, q)$ be a H\"older pair. Then 
$$|\langle \varphi, \psi\rangle| \leq \sum_{i=1}^{\binom dk} \sigma_i(\varphi) \sigma_i(\psi) \leq |\varphi|_p |\psi|_q.$$
\end{lemma}
\begin{proof}
It follows when we set $m := \binom dk$, $x_i := \sigma_i(\varphi)$, $y_i := \sigma_i(\psi)$, and $A_{ij} := \langle \xi_i(\varphi), \xi_j(\psi)\rangle$ in (\ref{permute to decreasing}).
\end{proof}


%%%%%%%%%%%%%%%%%%%%%%%
\section{Proving the main theorem}
\begin{proof}
Let $1 < p < \infty$.
We are going to define a strictly convex functional which approximates the comass, following Daskalopoulos and Uhlenbeck's approximation of the Lipschitz constant \cite{daskalopoulos2022}.

We first construct a singular value deomposition of a covector.
Let $\varphi$ be a $k$-covector at $x$ and let 
$$\sigma_1(\varphi) := \max_{v \in B_{x, k} M} \langle \varphi, v\rangle$$
and let $\xi_1(\varphi)$ be a $k$-blade which realizes the maximum.
Define 
$$\sigma_{n + 1}(\varphi) := \max_{\substack{v \in B_{x, k} M \\ v \perp \xi_1(\varphi), \dots, \xi_n(\varphi)}} \langle \varphi, v\rangle$$
and $\xi_{n + 1}(\varphi)$ a $k$-blade which realizes the maximum.
Thus we have $\sigma_n(\varphi) \geq \sigma_{n + 1}(\varphi)$.
We can then define the $p$th Schatten-von Neumann norm 
$$|\varphi|_p := \left(\sum_{n=1}^{\binom dk} \sigma_n(\varphi)^p\right)^{1/p}.$$
I think this quantity is a norm with strictly convex unit ball, since this is true of the Schatten-von Neumann norms on matrices.
This is the key step of the argument: \emph{we need to show that the we can approximate the pointwise comass by a norm with strictly convex unit ball}. \todo{Write it out}

We then introduce the $p$-energy
$$J_p(\varphi) := \int_M |\varphi(x)|_p^p \dif x$$
(where $\dif x$ is the Riemannian measure).
Then $J_p(\varphi) \sim \|\varphi\|_{L^p}^p$, hence $J_p$ is coercive on $L^p(M, \Omega^k_{\rm cl})$.
Moreover, since $|\varphi|_p$ has strictly convex unit ball, $J_p$ is strictly convex on each cohomology class in $L^p(M, \Omega^k_{\rm cl})$.
So by the direct method, for each $\rho \in H^k(M, \RR)$ there is a $\varphi_p \in L^p(M, \Omega^k_{\rm cl})$ representing $\rho$ which minimizes $J_p$.

If $\psi$ is cohomologous to $\varphi_p$ then by H\"older's inequality, applied first to $M$ and then to $\{1, \dots, \binom dk\}$ with its counting measure, we have
$$J_p(\varphi_p) \leq J_p(\psi) \leq \vol(M) \binom dk \esssup_{x \in M} \sigma_1(\psi(x))^p = \vol(M) \binom dk \Comass(\psi)^p.$$
In particular, $\|\varphi_p\|_{L^q}$ is bounded independently of $p \in (1, \infty)$ and $q \in (1, p]$.
Taking $p \to \infty$ and using Alaoglu's theorem, we see that for any $q \in (1, \infty)$, $\varphi_p \weakto \varphi$ along a subsequence in $L^q$.
We can then take the limits and use the fact that energy can only decrease along weak limits to deduce 
$$\Comass(\varphi) \leq \Comass(\psi).$$
Since $\psi$ was arbitrary, $\varphi$ minimizes the comass in $\rho$, hence $\Comass(\varphi) = 1$ and $\varphi$ is a calibration.
\end{proof}

Since $H^2(\CC \PP^2, \RR) \cong \RR$, I suspect that there is only one calibration $2$-form on $\CC \PP^2$, which is the Fubini-Study $2$-form.
This seems atypical for K\"ahler varieties, however, given the following.

\begin{corollary}
Let $M$ be a K3 surface. Then there is a calibration $2$-form $\varphi$ on $M$, which is not a K\"ahler $2$-form.
\end{corollary}
\begin{proof}
By Theorem \ref{existence of calibrations}, we can take $\varphi$ to represent the generator of $H^{2, 0}(M, \RR)$ after scaling it to have costable norm $1$.
\end{proof}


\appendix 
\section{Elementary inequalities}
\begin{lemma}
Suppose that $x, y \in \RR^m_+$ have decreasing entries, and for every $j \leq m$,
\begin{equation}\label{Ky Fan gives SvN hyp}
\sum_{i=1}^j x_j \leq \sum_{i=1}^j y_j.
\end{equation}
Then 
\begin{equation}\label{Ky Fan gives SvN concl}
\sum_{i=1}^m x_i^p \leq \sum_{i=1}^m y_i^p.
\end{equation}
\end{lemma}

\begin{lemma}
Suppose that $x, y \in \RR^m_+$ have decreasing entries, and $A \in \Orth(\RR^m)$. Then
\begin{equation}\label{permute to decreasing}
|\langle x, Ay\rangle| \leq \langle x, y\rangle.
\end{equation}
\end{lemma}
% https://math.stackexchange.com/questions/3075288/how-to-show-the-von-neumann-trace-inequality

\printbibliography

\end{document}
